# Default values for kube-node-ready
nameOverride: ""
fullnameOverride: ""

imagePullSecrets: []

priorityClassName: "system-node-critical"

securityContext:
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: true
  capabilities:
    drop:
      - ALL

podSecurityContext:
  runAsNonRoot: true
  runAsUser: 1000
  fsGroup: 1000

# Controller configuration
controller:
  replicas: 1  # Set to 2+ for high availability

  # High availability configuration
  leaderElection:
    enabled: true  # Enable leader election (required for replicas > 1)
    leaseDuration: 15s  # Duration that non-leader candidates will wait to force acquire leadership
    renewDeadline: 10s  # Duration the leader will retry refreshing leadership before giving up
    retryPeriod: 2s     # Duration the LeaderElector clients should wait between tries of actions

  image:
    repository: ghcr.io/imunhatep/kube-node-ready
    #tag: "0.2.6"
    pullPolicy: IfNotPresent

  # Service configuration
  service:
    type: ClusterIP  # Service type for controller metrics/health endpoints


  resources: {}
  #  requests:
  #    cpu: 50m
  #    memory: 64Mi
  #  limits:
  #    cpu: 200m  # Optional: can be omitted to avoid throttling
  #    memory: 128Mi  # Optional: recommended to prevent OOM issues

  serviceAccount:
    create: true
    annotations: {}
    name: ""

  podAnnotations: {}
  nodeSelector: {}
  tolerations: []
  affinity: {}

  # Health Configuration
  health:
    port: 8081

  metrics:
    enabled: true
    port: 8080

    # Prometheus ServiceMonitor (requires Prometheus Operator)
    serviceMonitor:
      enabled: false  # Set to true to create ServiceMonitor
      # namespace: monitoring  # Optional: namespace for ServiceMonitor (defaults to release namespace)
      interval: 30s  # Scrape interval
      scrapeTimeout: 10s  # Scrape timeout
      labels: {}  # Additional labels for ServiceMonitor (e.g., for Prometheus selector)
      # prometheus: kube-prometheus
      annotations: {}  # Additional annotations
      # relabelings: []  # Relabeling configs
      # metricRelabelings: []  # Metric relabeling configs
      # targetLabels: []  # Labels to transfer from service to metrics

  config:
    # Reconciliation Configuration
    reconciliation:
      intervalSeconds: 10  # Interval in seconds
      maxRetries: 5
      retryBackoff: exponential  # Options: exponential, linear

    # Node Management Configuration
    nodeManagement:
      deleteFailedNodes: false  # DANGEROUS: Delete nodes that fail verification
      taints:
        - key: node-ready/unverified
          value: "true"
          effect: NoSchedule
        # Add more taints as needed:
        # - key: node-ready/network-unverified
        #   value: "true"
        #   effect: NoExecute
      verifiedLabel:
        key: node-ready/verified
        value: "true"

    metrics:
      enabled: true
      port: 8080

    # Health Configuration
    health:
      port: 8081

    # Logging Configuration
    logging:
      level: info  # Options: debug, info, warn, error
      format: json  # Options: json, console

    # Kubernetes Client Configuration
    kubernetes:
      kubeconfigPath: ""  # Leave empty for in-cluster config
      qps: 50
      burst: 100

    # Worker Pod Configuration (passed to controller via ConfigMap)
    worker:
      image:
        repository: ghcr.io/imunhatep/kube-node-ready
        tag: "0.3.0"
        pullPolicy: IfNotPresent
      # Note: namespace is auto-detected from controller's environment
      # Uncomment to override (defaults to controller's namespace)
      # namespace: kube-system
      # Uncomment to override (defaults to worker's serviceAccountname)
      # serviceAccountName: kube-node-ready-worker
      timeoutSeconds: 300  # Timeout in seconds
      priorityClassName: system-node-critical
      resources:
        requests:
          cpu: "50m"
          memory: "64Mi"
        limits:
          memory: "128Mi"  # Optional: recommended to prevent OOM issues

      # Additional tolerations for worker pods (beyond automatic ones)
      # Useful when nodes have additional taints that should not be removed during validation
      tolerations: []
      # Examples:
      # tolerations:
      #  # Tolerate all taints - similar to DaemonSet behavior
      #   - operator: "Exists"
      #     effect: ""  # Empty effect means tolerate all effects
      #  # Tolerate specific taint
      #   - key: "workload-type"
      #     operator: "Equal"
      #     value: "batch"
      #     effect: "NoExecute"
      #     tolerationSeconds: 300

      # Custom init containers for additional verification checks
      # These run before the main verification container and must all succeed
      initContainers: []
      # Examples:
      # initContainers:
      #   - name: custom-network-check
      #     image: busybox:latest
      #     command: ["/bin/sh", "-c"]
      #     args: ["ping -c 3 internal-service.company.com"]
      #   - name: storage-check
      #     image: busybox:latest
      #     command: ["/bin/sh", "-c"]
      #     args: ["test -d /host/var/lib/kubelet"]
      #     volumeMounts:
      #       - name: host-kubelet
      #         mountPath: /host/var/lib/kubelet
      #         readOnly: true
      #     securityContext:
      #       privileged: false
      #       readOnlyRootFilesystem: true
      #   - name: gpu-check
      #     image: nvidia/cuda:11.0-base
      #     command: ["nvidia-smi"]
      #     resources:
      #       limits:
      #         nvidia.com/gpu: 1

      # Job Configuration (optional - provides better reliability and auto-retry)
      job:
        # Job timeout - if not specified, falls back to timeoutSeconds above
        activeDeadlineSeconds: 300
        # Number of retries for failed pods (Kubernetes handles this automatically)
        backoffLimit: 2
        # Number of successful completions required
        completions: 1
        # Number of parallel pods (should be 1 for node verification)
        parallelism: 1
        # Auto-cleanup completed jobs after specified seconds (optional)
        # ttlSecondsAfterFinished: 600

# Worker Helm resource configuration (for generating Kubernetes resources)
# This section controls what Kubernetes resources are created by Helm
worker:
  # Service account configuration for worker pods
  serviceAccount:
    # Specifies whether a service account should be created for worker pods
    create: true
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ""

  # Worker runtime configuration (mounted into worker pods via ConfigMap)
  # This configuration is used by worker pods when they execute
  config:
    # Worker runtime configuration
    maxRetries: 1
    retryBackoff: linear  # Options: exponential, linear

    # Check timeout for individual checks (DNS, network, K8s API)
    checkTimeoutSeconds: 5

    # DNS domains to test during node verification
    dnsTestDomains:
      - kubernetes.default.svc.cluster.local
      - google.com

    # Optional: cluster DNS IP address
    clusterDnsIp: ""

    # Logging configuration for worker pods
    logging:
      level: info  # Options: debug, info, warn, error
      format: json  # Options: json, console

